\section{Introduction}

Anomaly detection, describes a field of methods for identifying observations as 
    \emph{anomalous};
    a term that requires defining. 
    For this paper, following 
    the general trend in the literature, we define anomalies as observations that 
    are in some manner different than non-anomalous data. We interpret 
    this to say that anomalies are data that were not produced by the same 
    generating distribution as non-anomalous data, and as such, we would expect 
    observations found in regions of relative data sparsity to be more likely to 
    be anomalous than those observations found in regions of high data 
    abundance.  We characterize this assumption as \emph{anomalies stand apart}.
    In the literature as here, the term \emph{normal data} is used to refer to data 
    which are not anomalous.  Normal data tend to cluster into homogenous groups, 
    but anomalous data are heterogenous in their differences. 
    
Alternative names for the field of anomaly detection include \emph{outlier} detection, and 
    \emph{novelty} detection, though these terms have their own nuances.
    Outliers are characterized as observations that are in some manner 
    far from normal data.  In a regression context, they may have
    large fitted residuals, or exert large influence on model fits.  Novelties
    in contrast are data coming from a distribution that has not been seen
    before.  A novelty detection application will then assume a clean 
    training data set containing no anomalies, and identify observations not
    belonging to the distribution as trained.  \cite{Chandola2009} refer to 
    this practice as semi-supervised anomaly detection. For our purpose, we do 
    not assume the existence of labels in the training 
    dataset, and seek an algorithm that can produce anomaly scores in the absence 
    of class labels. As such, we will offer a brief overview of unsupervised 
    anomaly detection methods, as well as discussion of the methods we are 
    proposing here as competing models.
    
% EOF